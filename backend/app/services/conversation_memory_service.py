"""
Conversation Memory Service â€” KullanÄ±cÄ± Seviyesinde HafÄ±za.

Tek asistan, farklÄ± projeler modeli:
- Her sohbet sonunda Ã¶zet Ã§Ä±kar â†’ user hafÄ±zasÄ±na kaydet
- Yeni sohbette geÃ§miÅŸ Ã¶zetleri context'e ekle
- BaÅŸarÄ±lÄ± prompt'larÄ± hatÄ±rla (Self-Learning)
- KullanÄ±cÄ± tercihlerini Ã¶ÄŸren
"""
import json
import uuid
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta

from openai import AsyncOpenAI
from app.core.config import settings


class ConversationMemoryService:
    """KullanÄ±cÄ± seviyesinde hafÄ±za â€” projeler arasÄ± hatÄ±rlama."""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
    
    # ===============================
    # SOHBET Ã–ZETLEMESÄ°
    # ===============================
    
    async def summarize_conversation(
        self,
        messages: List[Dict[str, str]],
        session_title: str = ""
    ) -> str:
        """
        Sohbet geÃ§miÅŸini Ã¶zetle.
        Her sohbet kapandÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r.
        """
        if not messages or len(messages) < 2:
            return ""
        
        # Son 30 mesajÄ± al
        recent = messages[-30:]
        conversation_text = "\n".join([
            f"{'KullanÄ±cÄ±' if m['role'] == 'user' else 'Asistan'}: {m['content'][:200]}"
            for m in recent
        ])
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",  # HÄ±zlÄ± ve ucuz
                messages=[
                    {
                        "role": "system",
                        "content": """Bir sohbet Ã¶zetleme sistemisÄ°n. AÅŸaÄŸÄ±daki sohbeti Ã‡OK KISA Ã¶zetle (max 3 cÃ¼mle):
- Ne yapÄ±ldÄ±?
- Hangi entity'ler/markalar kullanÄ±ldÄ±?
- KullanÄ±cÄ± neyi beÄŸendi/beÄŸenmedi?
- Hangi stil/format tercih edildi?

TÃ¼rkÃ§e yaz. Sadece Ã¶zet, baÅŸka bir ÅŸey yazma."""
                    },
                    {
                        "role": "user",
                        "content": f"Proje: {session_title}\n\nSohbet:\n{conversation_text}"
                    }
                ],
                max_tokens=150,
                temperature=0.3
            )
            
            summary = response.choices[0].message.content.strip()
            print(f"ðŸ“ Sohbet Ã¶zeti oluÅŸturuldu: {summary[:80]}...")
            return summary
            
        except Exception as e:
            print(f"âš ï¸ Ã–zet oluÅŸturma hatasÄ±: {e}")
            return ""
    
    async def save_conversation_summary(
        self,
        db,
        user_id: uuid.UUID,
        session_id: uuid.UUID,
        summary: str
    ):
        """Ã–zeti Redis + DB'ye kaydet."""
        from app.core.cache import cache
        
        # Redis'e kaydet (hÄ±zlÄ± eriÅŸim)
        memory_key = f"user_memory:{user_id}"
        existing = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        existing["summaries"].append({
            "session_id": str(session_id),
            "summary": summary,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        # Son 20 Ã¶zeti tut
        if len(existing["summaries"]) > 20:
            existing["summaries"] = existing["summaries"][-20:]
        
        await cache.set_json(memory_key, existing, ttl=604800)  # 7 gÃ¼n
        print(f"ðŸ’¾ HafÄ±za kaydedildi: user={str(user_id)[:8]}...")
    
    # ===============================
    # KULLANICI HAFIZASÄ± YÃœKLEME
    # ===============================
    
    async def get_user_memory(self, user_id: uuid.UUID) -> Dict[str, Any]:
        """KullanÄ±cÄ±nÄ±n tÃ¼m hafÄ±zasÄ±nÄ± getir."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key)
        
        if not memory:
            return {
                "summaries": [],
                "preferences": {},
                "successful_prompts": [],
                "style_preferences": {}
            }
        
        return memory
    
    async def build_memory_context(self, user_id: uuid.UUID) -> str:
        """
        GeÃ§miÅŸ hafÄ±zayÄ± system prompt'a eklenecek context'e dÃ¶nÃ¼ÅŸtÃ¼r.
        Agent bu bilgiyle kullanÄ±cÄ±yÄ± "tanÄ±r".
        """
        memory = await self.get_user_memory(user_id)
        
        parts = []
        
        # GeÃ§miÅŸ sohbet Ã¶zetleri
        if memory.get("summaries"):
            recent_summaries = memory["summaries"][-5:]  # Son 5 proje
            summaries_text = "\n".join([
                f"- {s['summary']}" for s in recent_summaries
            ])
            parts.append(f"ðŸ“‹ SON PROJELER:\n{summaries_text}")
        
        # Tercihler
        if memory.get("preferences"):
            prefs = memory["preferences"]
            prefs_text = ", ".join([f"{k}: {v}" for k, v in prefs.items()])
            parts.append(f"âš™ï¸ TERCÄ°HLER: {prefs_text}")
        
        # BaÅŸarÄ±lÄ± prompt'lar
        if memory.get("successful_prompts"):
            recent_prompts = memory["successful_prompts"][-3:]
            prompts_text = "\n".join([
                f"- \"{p['prompt'][:100]}\" (skor: {p.get('score', '?')})"
                for p in recent_prompts
            ])
            parts.append(f"â­ BAÅžARILI PROMPTLAR:\n{prompts_text}")
        
        # Stil tercihleri
        if memory.get("style_preferences"):
            style = memory["style_preferences"]
            style_text = ", ".join([f"{k}: {v}" for k, v in style.items()])
            parts.append(f"ðŸŽ¨ STÄ°L: {style_text}")
        
        if not parts:
            return ""
        
        return "\n\n".join(parts)
    
    # ===============================
    # SELF-LEARNING: BAÅžARILI PROMPT'LAR
    # ===============================
    
    async def save_successful_prompt(
        self,
        user_id: uuid.UUID,
        prompt: str,
        result_url: str,
        score: int,
        asset_type: str = "image"
    ):
        """KullanÄ±cÄ± beÄŸendiÄŸinde prompt'u hafÄ±zaya kaydet."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        memory["successful_prompts"].append({
            "prompt": prompt,
            "result_url": result_url,
            "score": score,
            "asset_type": asset_type,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        # Son 50 baÅŸarÄ±lÄ± prompt
        if len(memory["successful_prompts"]) > 50:
            memory["successful_prompts"] = memory["successful_prompts"][-50:]
        
        await cache.set_json(memory_key, memory, ttl=604800)
        print(f"â­ BaÅŸarÄ±lÄ± prompt kaydedildi: '{prompt[:50]}...' (skor: {score})")
    
    async def find_similar_prompts(
        self,
        user_id: uuid.UUID,
        query: str,
        limit: int = 3
    ) -> List[Dict[str, Any]]:
        """GeÃ§miÅŸ baÅŸarÄ±lÄ± prompt'lardan benzerleri bul."""
        memory = await self.get_user_memory(user_id)
        prompts = memory.get("successful_prompts", [])
        
        if not prompts:
            return []
        
        # Basit kelime eÅŸleÅŸtirmesi (Pinecone yoksa fallback)
        query_words = set(query.lower().split())
        scored = []
        
        for p in prompts:
            prompt_words = set(p["prompt"].lower().split())
            overlap = len(query_words & prompt_words)
            if overlap > 0:
                scored.append((overlap, p))
        
        scored.sort(key=lambda x: x[0], reverse=True)
        return [item[1] for item in scored[:limit]]
    
    # ===============================
    # TERCÄ°H Ã–ÄžRENME
    # ===============================
    
    async def update_preferences(
        self,
        user_id: uuid.UUID,
        key: str,
        value: str
    ):
        """KullanÄ±cÄ± tercihini gÃ¼ncelle."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        memory["preferences"][key] = value
        await cache.set_json(memory_key, memory, ttl=604800)
    
    async def update_style_preference(
        self,
        user_id: uuid.UUID,
        style_key: str,
        style_value: str
    ):
        """Stil tercihini kaydet."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        memory["style_preferences"][style_key] = style_value
        await cache.set_json(memory_key, memory, ttl=604800)


# Singleton
conversation_memory = ConversationMemoryService()
