"""
Conversation Memory Service â€” KullanÄ±cÄ± Seviyesinde HafÄ±za.

Tek asistan, farklÄ± projeler modeli:
- Her sohbet sonunda Ã¶zet Ã§Ä±kar â†’ user hafÄ±zasÄ±na kaydet
- Yeni sohbette geÃ§miÅŸ Ã¶zetleri context'e ekle
- BaÅŸarÄ±lÄ± prompt'larÄ± hatÄ±rla (Self-Learning)
- KullanÄ±cÄ± tercihlerini Ã¶ÄŸren
"""
import json
import uuid
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta

from openai import AsyncOpenAI
from app.core.config import settings


class ConversationMemoryService:
    """KullanÄ±cÄ± seviyesinde hafÄ±za â€” projeler arasÄ± hatÄ±rlama."""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
    
    # ===============================
    # SOHBET Ã–ZETLEMESÄ°
    # ===============================
    
    async def summarize_conversation(
        self,
        messages: List[Dict[str, str]],
        session_title: str = ""
    ) -> str:
        """
        Sohbet geÃ§miÅŸini Ã¶zetle.
        Her sohbet kapandÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r.
        """
        if not messages or len(messages) < 2:
            return ""
        
        # Son 30 mesajÄ± al
        recent = messages[-30:]
        conversation_text = "\n".join([
            f"{'KullanÄ±cÄ±' if m['role'] == 'user' else 'Asistan'}: {m['content'][:200]}"
            for m in recent
        ])
        
        try:
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",  # HÄ±zlÄ± ve ucuz
                messages=[
                    {
                        "role": "system",
                        "content": """Bir sohbet Ã¶zetleme sistemisÄ°n. AÅŸaÄŸÄ±daki sohbeti Ã‡OK KISA Ã¶zetle (max 3 cÃ¼mle):
- Ne yapÄ±ldÄ±?
- Hangi entity'ler/markalar kullanÄ±ldÄ±?
- KullanÄ±cÄ± neyi beÄŸendi/beÄŸenmedi?
- Hangi stil/format tercih edildi?

TÃ¼rkÃ§e yaz. Sadece Ã¶zet, baÅŸka bir ÅŸey yazma."""
                    },
                    {
                        "role": "user",
                        "content": f"Proje: {session_title}\n\nSohbet:\n{conversation_text}"
                    }
                ],
                max_tokens=150,
                temperature=0.3
            )
            
            summary = response.choices[0].message.content.strip()
            print(f"ğŸ“ Sohbet Ã¶zeti oluÅŸturuldu: {summary[:80]}...")
            return summary
            
        except Exception as e:
            print(f"âš ï¸ Ã–zet oluÅŸturma hatasÄ±: {e}")
            return ""
    
    async def save_conversation_summary(
        self,
        db,
        user_id: uuid.UUID,
        session_id: uuid.UUID,
        summary: str
    ):
        """Ã–zeti Redis + DB'ye kaydet."""
        from app.core.cache import cache
        
        # Redis'e kaydet (hÄ±zlÄ± eriÅŸim)
        memory_key = f"user_memory:{user_id}"
        existing = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        existing["summaries"].append({
            "session_id": str(session_id),
            "summary": summary,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        # Son 20 Ã¶zeti tut
        if len(existing["summaries"]) > 20:
            existing["summaries"] = existing["summaries"][-20:]
        
        await cache.set_json(memory_key, existing, ttl=604800)  # 7 gÃ¼n
        print(f"ğŸ’¾ HafÄ±za kaydedildi: user={str(user_id)[:8]}...")
    
    # ===============================
    # KULLANICI HAFIZASÄ± YÃœKLEME
    # ===============================
    
    async def get_user_memory(self, user_id: uuid.UUID) -> Dict[str, Any]:
        """KullanÄ±cÄ±nÄ±n tÃ¼m hafÄ±zasÄ±nÄ± getir."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key)
        
        if not memory:
            return {
                "summaries": [],
                "preferences": {},
                "successful_prompts": [],
                "style_preferences": {},
                "core_memories": []
            }
        
        return memory
    
    async def build_memory_context(self, user_id: uuid.UUID) -> str:
        """
        GeÃ§miÅŸ hafÄ±zayÄ± system prompt'a eklenecek context'e dÃ¶nÃ¼ÅŸtÃ¼r.
        Agent bu bilgiyle kullanÄ±cÄ±yÄ± "tanÄ±r".
        """
        memory = await self.get_user_memory(user_id)
        
        parts = []
        
        # Core Memories (KullanÄ±cÄ± GerÃ§ekleri)
        if memory.get("core_memories"):
            core_text = "\n".join([f"- {m['fact']} (Kategori: {m.get('category', 'genel')})" for m in memory["core_memories"][-10:]])
            parts.append(f"ğŸ‘¤ KULLANICI HAKKINDA BÄ°LDÄ°KLERÄ°N (CORE MEMORY):\n{core_text}")
        
        # GeÃ§miÅŸ sohbet Ã¶zetleri
        if memory.get("summaries"):
            recent_summaries = memory["summaries"][-5:]  # Son 5 proje
            summaries_text = "\n".join([
                f"- {s['summary']}" for s in recent_summaries
            ])
            parts.append(f"ğŸ“‹ SON PROJELER:\n{summaries_text}")
        
        # Tercihler
        if memory.get("preferences"):
            prefs = memory["preferences"]
            prefs_text = ", ".join([f"{k}: {v}" for k, v in prefs.items()])
            parts.append(f"âš™ï¸ TERCÄ°HLER: {prefs_text}")
        
        # BaÅŸarÄ±lÄ± prompt'lar
        if memory.get("successful_prompts"):
            recent_prompts = memory["successful_prompts"][-3:]
            prompts_text = "\n".join([
                f"- \"{p['prompt'][:100]}\" (skor: {p.get('score', '?')})"
                for p in recent_prompts
            ])
            parts.append(f"â­ BAÅARILI PROMPTLAR:\n{prompts_text}")
        
        # Stil tercihleri
        if memory.get("style_preferences"):
            style = memory["style_preferences"]
            style_text = ", ".join([f"{k}: {v}" for k, v in style.items()])
            parts.append(f"ğŸ¨ STÄ°L: {style_text}")
        
        if not parts:
            return ""
        
        return "\n\n".join(parts)
    
    # ===============================
    # SELF-LEARNING: BAÅARILI PROMPT'LAR
    # ===============================
    
    async def save_successful_prompt(
        self,
        user_id: uuid.UUID,
        prompt: str,
        result_url: str,
        score: int,
        asset_type: str = "image"
    ):
        """KullanÄ±cÄ± beÄŸendiÄŸinde prompt'u hafÄ±zaya kaydet."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        memory["successful_prompts"].append({
            "prompt": prompt,
            "result_url": result_url,
            "score": score,
            "asset_type": asset_type,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        # Son 50 baÅŸarÄ±lÄ± prompt
        if len(memory["successful_prompts"]) > 50:
            memory["successful_prompts"] = memory["successful_prompts"][-50:]
        
        await cache.set_json(memory_key, memory, ttl=604800)
        print(f"â­ BaÅŸarÄ±lÄ± prompt kaydedildi: '{prompt[:50]}...' (skor: {score})")
    
    async def find_similar_prompts(
        self,
        user_id: uuid.UUID,
        query: str,
        limit: int = 3
    ) -> List[Dict[str, Any]]:
        """GeÃ§miÅŸ baÅŸarÄ±lÄ± prompt'lardan benzerleri bul."""
        memory = await self.get_user_memory(user_id)
        prompts = memory.get("successful_prompts", [])
        
        if not prompts:
            return []
        
        # Basit kelime eÅŸleÅŸtirmesi (Pinecone yoksa fallback)
        query_words = set(query.lower().split())
        scored = []
        
        for p in prompts:
            prompt_words = set(p["prompt"].lower().split())
            overlap = len(query_words & prompt_words)
            if overlap > 0:
                scored.append((overlap, p))
        
        scored.sort(key=lambda x: x[0], reverse=True)
        return [item[1] for item in scored[:limit]]
    
    # ===============================
    # TERCÄ°H Ã–ÄRENME
    # ===============================
    
    async def update_preferences(
        self,
        user_id: uuid.UUID,
        key: str,
        value: str
    ):
        """KullanÄ±cÄ± tercihini gÃ¼ncelle."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        memory["preferences"][key] = value
        await cache.set_json(memory_key, memory, ttl=604800)
    
    async def update_style_preference(
        self,
        user_id: uuid.UUID,
        style_key: str,
        style_value: str
    ):
        """Stil tercihini kaydet."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {}
        }
        
        memory["style_preferences"][style_key] = style_value
        await cache.set_json(memory_key, memory, ttl=604800)

    # ===============================
    # CORE MEMORY (Ã‡EKÄ°RDEK HAFIZA)
    # ===============================
    
    async def save_core_memory(
        self,
        user_id: uuid.UUID,
        category: str,
        fact: str
    ):
        """KullanÄ±cÄ±nÄ±n temel bir Ã¶zelliÄŸini veya kuralÄ±nÄ± kalÄ±cÄ± hafÄ±zaya kaydet."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key) or {
            "summaries": [],
            "preferences": {},
            "successful_prompts": [],
            "style_preferences": {},
            "core_memories": []
        }
        
        if "core_memories" not in memory:
            memory["core_memories"] = []
            
        memory["core_memories"].append({
            "category": category,
            "fact": fact,
            "timestamp": datetime.utcnow().isoformat()
        })
        
        await cache.set_json(memory_key, memory, ttl=604800)
        print(f"ğŸ§  Core memory eklendi ({category}): {fact[:50]}...")

    async def delete_core_memory(self, user_id: uuid.UUID, fact_query: str) -> bool:
        """Belirli bir cÃ¼mleye veya iÃ§eriÄŸe uyan hafÄ±zayÄ± sil."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key)
        
        if not memory or "core_memories" not in memory:
            return False
            
        initial_length = len(memory["core_memories"])
        
        # EÄŸer fact_query tam eÅŸleÅŸiyorsa veya iÃ§eriyorsa sil (case-insensitive)
        memory["core_memories"] = [
            m for m in memory["core_memories"]
            if fact_query.lower() not in m["fact"].lower()
        ]
        
        if len(memory["core_memories"]) < initial_length:
            await cache.set_json(memory_key, memory, ttl=604800)
            print(f"ğŸ—‘ï¸ Core memory silindi: '{fact_query}'")
            return True
            
        return False
        
    async def clear_core_memories(self, user_id: uuid.UUID):
        """KullanÄ±cÄ±nÄ±n tÃ¼m Ã§ekirdek hafÄ±zasÄ±nÄ± temizle."""
        from app.core.cache import cache
        
        memory_key = f"user_memory:{user_id}"
        memory = await cache.get_json(memory_key)
        
        if memory and "core_memories" in memory:
            memory["core_memories"] = []
            await cache.set_json(memory_key, memory, ttl=604800)
            print("ğŸ§¹ TÃ¼m core memory temizlendi.")

# Singleton
conversation_memory = ConversationMemoryService()
