"""
fal.ai Plugin V2 - Yeni plugin sistemine uyumlu fal.ai adapter.

Bu plugin PluginBase'den tÃ¼retilir ve plugin_loader tarafÄ±ndan yÃ¶netilir.

V3 Upgrade (17 Åubat 2026):
- Smart Model Router: Ä°stek tipine gÃ¶re en iyi modeli otomatik seÃ§
- Auto-Retry Fallback: BaÅŸarÄ±sÄ±z olursa alternatif modelle dene
- FLUX 2 Flex: Metin/tipografi render iÃ§in
- FLUX Kontext: AkÄ±llÄ± lokal gÃ¶rsel dÃ¼zenleme
- Veo 3.1: Google'Ä±n en kaliteli video modeli
- Outpainting: GÃ¶rseli geniÅŸletme
- Style Transfer: Sanatsal stil uygulama
"""
import os
import time
import asyncio
import logging
from typing import Optional, Any
import fal_client

from app.core.config import settings
from app.services.plugins.plugin_base import (
    PluginBase, PluginInfo, PluginResult, PluginCategory
)
from app.services.plugins.fal_models import ALL_MODELS, ModelCategory as FalModelCategory

logger = logging.getLogger(__name__)


class FalPluginV2(PluginBase):
    """
    fal.ai Plugin - GÃ¶rsel ve video Ã¼retim servisi.
    
    Ã–zellikler:
    - 25+ AI modeli (gÃ¶rsel, video, upscale, edit)
    - AkÄ±llÄ± model seÃ§imi
    - YÃ¼z tutarlÄ±lÄ±ÄŸÄ± (face swap)
    """
    
    def __init__(self):
        super().__init__()
        
        # API key ayarla
        if settings.FAL_KEY:
            os.environ["FAL_KEY"] = settings.FAL_KEY
    
    @property
    def info(self) -> PluginInfo:
        return PluginInfo(
            name="fal_ai",
            display_name="fal.ai",
            version="3.0.0",
            description="GÃ¶rsel ve video Ã¼retimi iÃ§in fal.ai AI modelleri (Smart Router + Auto-Retry)",
            category=PluginCategory.IMAGE_GENERATION,
            author="Pepper Root",
            requires_api_key=True,
            api_key_env_var="FAL_KEY",
            capabilities=[
                "image_generation",
                "video_generation",
                "image_editing",
                "video_editing",
                "upscaling",
                "face_swap",
                "background_removal",
                "outpainting",
                "style_transfer",
            ],
            config_schema={
                "default_model": {"type": "string", "default": "fal-ai/nano-banana-pro"},
                "default_resolution": {"type": "string", "default": "1K"},
            }
        )
    
    def get_available_actions(self) -> list[str]:
        return [
            "generate_image",
            "generate_video",
            "edit_video",
            "edit_image",
            "upscale_image",
            "upscale_video",
            "remove_background",
            "face_swap",
            "smart_generate_with_face",
            "outpaint_image",
            "apply_style",
        ]
    
    async def execute(self, action: str, params: dict) -> PluginResult:
        """
        Ana Ã§alÄ±ÅŸma metodu - action'a gÃ¶re ilgili fonksiyonu Ã§aÄŸÄ±r.
        """
        start_time = time.time()
        
        if not self.is_enabled:
            return PluginResult(
                success=False,
                error="Plugin devre dÄ±ÅŸÄ±"
            )
        
        # Parametre doÄŸrulama
        valid, error = self.validate_params(action, params)
        if not valid:
            return PluginResult(success=False, error=error)
        
        try:
            # Action'a gÃ¶re yÃ¶nlendir
            if action == "generate_image":
                result = await self._generate_image(params)
            elif action == "generate_video":
                result = await self._generate_video(params)
            elif action == "edit_video":
                result = await self._edit_video(params)
            elif action == "edit_image":
                result = await self._edit_image(params)
            elif action == "upscale_image":
                result = await self._upscale_image(params)
            elif action == "upscale_video":
                result = await self._upscale_video(params)
            elif action == "remove_background":
                result = await self._remove_background(params)
            elif action == "face_swap":
                result = await self._face_swap(params)
            elif action == "smart_generate_with_face":
                result = await self._smart_generate_with_face(params)
            elif action == "outpaint_image":
                result = await self._outpaint_image(params)
            elif action == "apply_style":
                result = await self._apply_style(params)
            else:
                return PluginResult(
                    success=False,
                    error=f"Bilinmeyen action: {action}"
                )
            
            execution_time = (time.time() - start_time) * 1000
            
            return PluginResult(
                success=result.get("success", False),
                data=result,
                error=result.get("error"),
                execution_time_ms=execution_time,
            )
            
        except Exception as e:
            return PluginResult(
                success=False,
                error=str(e),
                execution_time_ms=(time.time() - start_time) * 1000
            )
    
    async def health_check(self) -> bool:
        """fal.ai API baÄŸlantÄ±sÄ±nÄ± kontrol et."""
        try:
            # Basit bir ping
            if not settings.FAL_KEY:
                return False
            return True
        except:
            return False
    
    # ===============================
    # SMART MODEL ROUTER
    # ===============================
    
    # Model fallback zincirleri â€” bir model baÅŸarÄ±sÄ±z olursa sÄ±radaki denenir
    IMAGE_MODEL_CHAIN = [
        "fal-ai/nano-banana-pro",
        "fal-ai/flux-2-flex",
    ]
    
    VIDEO_MODEL_CHAIN = [
        {"i2v": "fal-ai/kling-video/v3/pro/image-to-video", "t2v": "fal-ai/kling-video/v3/pro/text-to-video"},
        {"i2v": "fal-ai/veo3.1/image-to-video", "t2v": "fal-ai/kling-video/v2.5-turbo/pro/text-to-video"},
    ]
    
    EDIT_MODEL_CHAIN = [
        "fal-ai/flux-pro/kontext",
        "fal-ai/omnigen-v1",
        "fal-ai/flux-general/inpainting",
    ]
    
    def _select_image_model(self, prompt: str) -> str:
        """
        Smart Model Router â€” prompt'a gÃ¶re en iyi gÃ¶rsel modelini seÃ§.
        
        - Metin/logo/tipografi â†’ FLUX 2 Flex (metin render'da en iyi)
        - FotogerÃ§ekÃ§i/genel â†’ Nano Banana Pro (hÄ±z + kalite dengesi)
        """
        prompt_lower = prompt.lower()
        
        # Metin/tipografi/logo gerektiren promptlar
        text_keywords = [
            "text", "logo", "typography", "yazÄ±", "metin", "slogan",
            "poster", "banner", "afiÅŸ", "kart", "card", "title",
            "heading", "baÅŸlÄ±k", "label", "etiket", "sign", "tabela",
            "writing", "font", "letter", "harf",
        ]
        
        if any(kw in prompt_lower for kw in text_keywords):
            logger.info("ğŸ¯ Smart Router: FLUX 2 Flex seÃ§ildi (tipografi)")
            return "fal-ai/flux-2-flex"
        
        # VarsayÄ±lan: Nano Banana Pro
        logger.info("ğŸ¯ Smart Router: Nano Banana Pro seÃ§ildi (varsayÄ±lan)")
        return "fal-ai/nano-banana-pro"
    
    def _select_video_model(self, prompt: str, has_image: bool) -> str:
        """
        Smart Video Model Router.
        
        - Genel â†’ Kling 3.0 Pro (varsayÄ±lan, en gÃ¼venilir)
        - Sinematik/gerÃ§ekÃ§i â†’ Veo 3.1 (Google'Ä±n en iyisi)
        """
        prompt_lower = prompt.lower()
        mode = "i2v" if has_image else "t2v"
        
        # Sinematik/gerÃ§ekÃ§i istekler
        cinematic_keywords = [
            "cinematic", "sinematik", "realistic", "gerÃ§ekÃ§i",
            "film", "movie", "documentary", "belgesel",
            "slow motion", "yavaÅŸ Ã§ekim", "epic",
        ]
        
        if has_image and any(kw in prompt_lower for kw in cinematic_keywords):
            logger.info("ğŸ¯ Smart Router: Veo 3.1 seÃ§ildi (sinematik)")
            return "fal-ai/veo3.1/image-to-video"
        
        # VarsayÄ±lan: Kling 3.0 Pro
        return self.VIDEO_MODEL_CHAIN[0][mode]
    
    # ===============================
    # PRIVATE METHODS
    # ===============================
    
    async def _generate_image(self, params: dict) -> dict:
        """
        AkÄ±llÄ± GÃ¶rsel Ãœretim â€” Smart Router + Auto-Retry Fallback.
        
        1. Smart Router prompt'a gÃ¶re en iyi modeli seÃ§er
        2. BaÅŸarÄ±sÄ±z olursa fallback zincirine geÃ§er
        """
        prompt = params.get("prompt", "")
        aspect_ratio = params.get("aspect_ratio", "1:1")
        resolution = params.get("resolution", "1K")
        preferred_model = params.get("model")  # Opsiyonel: Agent belirli model isteyebilir
        
        # Resolution mapping
        resolution_map = {
            "1K": {"square": 1024, "landscape": (1280, 720), "portrait": (720, 1280)},
            "2K": {"square": 1536, "landscape": (1920, 1080), "portrait": (1080, 1920)},
            "4K": {"square": 2048, "landscape": (2560, 1440), "portrait": (1440, 2560)},
        }
        
        # Aspect ratio mapping
        aspect_map = {
            "1:1": "square", "16:9": "landscape", "9:16": "portrait",
            "4:3": "landscape", "3:4": "portrait",
        }
        
        aspect_type = aspect_map.get(aspect_ratio, "square")
        res_config = resolution_map.get(resolution, resolution_map["1K"])
        
        if aspect_type == "square":
            image_size = {"width": res_config["square"], "height": res_config["square"]}
        else:
            w, h = res_config[aspect_type]
            image_size = {"width": w, "height": h}
        
        # Smart Model Router: En iyi modeli seÃ§
        selected_model = preferred_model or self._select_image_model(prompt)
        
        # Auto-Retry Fallback zinciri oluÅŸtur
        models_to_try = [selected_model]
        for m in self.IMAGE_MODEL_CHAIN:
            if m not in models_to_try:
                models_to_try.append(m)
        
        last_error = None
        for model_id in models_to_try:
            try:
                logger.info(f"ğŸ–¼ï¸ GÃ¶rsel Ã¼retim deneniyor: {model_id}")
                
                # FLUX 2 Flex farklÄ± parametre yapÄ±sÄ± kullanÄ±r
                if "flux-2" in model_id:
                    arguments = {
                        "prompt": prompt,
                        "image_size": image_size,
                        "num_images": 1,
                        "num_inference_steps": 30,
                        "guidance_scale": 5.0,
                        "output_format": "png",
                        "enable_safety_checker": False,
                    }
                else:
                    arguments = {
                        "prompt": prompt,
                        "image_size": image_size,
                        "num_images": 1,
                        "output_format": "png",
                        "enable_safety_checker": False,
                    }
                
                result = await fal_client.subscribe_async(
                    model_id,
                    arguments=arguments,
                    with_logs=True,
                )
                
                if result and "images" in result and len(result["images"]) > 0:
                    logger.info(f"âœ… GÃ¶rsel Ã¼retildi: {model_id}")
                    return {
                        "success": True,
                        "image_url": result["images"][0]["url"],
                        "model": model_id.split("/")[-1],
                        "model_id": model_id,
                    }
                    
            except Exception as e:
                last_error = str(e)
                logger.warning(f"âš ï¸ {model_id} baÅŸarÄ±sÄ±z: {e}. Sonraki model deneniyor...")
                continue
        
        return {"success": False, "error": f"TÃ¼m modeller baÅŸarÄ±sÄ±z. Son hata: {last_error}"}
    
    async def _generate_video(self, params: dict) -> dict:
        """
        Smart Multi-Model Video Generation (Kling, Luma, Runway, Minimax)
        """
        prompt = params.get("prompt", "")
        image_url = params.get("image_url")  # Opsiyonel - image-to-video
        duration = params.get("duration", "5")  
        preferred_model = params.get("model", "kling")  # VarsayÄ±lan kling
        
        has_image = bool(image_url)
        mode = "i2v" if has_image else "t2v"
        
        # Model Enum -> Fal.ai Endpoint Mapping
        # Not: Fal.ai endpoint isimleri sÃ¼rekli deÄŸiÅŸebilir, en stabil bilinenleri kullanÄ±yoruz
        model_endpoints = {
            "kling": {
                "i2v": "fal-ai/kling-video/v1/standard/image-to-video",
                "t2v": "fal-ai/kling-video/v1/standard/text-to-video"
            },
            "luma": {
                "i2v": "fal-ai/luma-dream-machine/image-to-video",
                "t2v": "fal-ai/luma-dream-machine"
            },
            "runway": {
                "i2v": "fal-ai/runway-gen3/turbo/image-to-video",
                "t2v": "fal-ai/runway-gen3/turbo/text-to-video"
            },
            "minimax": {
                # Minimax Hailuo AI genelde tek endpoint kullanÄ±r i2v/t2v
                "i2v": "fal-ai/minimax-video/image-to-video",
                "t2v": "fal-ai/minimax-video"
            }
        }
        
        # GÃ¼venlik kontrolÃ¼
        if preferred_model not in model_endpoints:
            logger.warning(f"Bilinmeyen video modeli '{preferred_model}'. Kling'e fallback yapÄ±lÄ±yor.")
            preferred_model = "kling"
            
        selected_endpoint = model_endpoints[preferred_model][mode]
        logger.info(f"ğŸ¥ Video model seÃ§ildi: {preferred_model.upper()} ({selected_endpoint})")
        
        try:
            arguments = {
                "prompt": prompt,
                "duration": duration if preferred_model != "runway" else (5 if int(duration) <= 5 else 10), # Runway genelde katÄ± duration alÄ±r
                "aspect_ratio": params.get("aspect_ratio", "16:9"),
            }
            
            if has_image:
                # Video API'leri (Ã¶zellik Kling) iÃ§in Ã§Ã¶zÃ¼nÃ¼rlÃ¼k limitleri var. (Ã¶rn: max 1280x720 civarÄ± bir ÅŸeye sÄ±ÄŸmalÄ±)
                try:
                    import httpx
                    import tempfile
                    import os as os_module
                    from PIL import Image
                    import base64
                    
                    max_dim = 1280
                    async with httpx.AsyncClient(timeout=30) as client:
                        resp = await client.get(image_url)
                        resp.raise_for_status()
                    
                    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
                        tmp.write(resp.content)
                        tmp_path = tmp.name
                        
                    with Image.open(tmp_path) as img:
                        orig_w, orig_h = img.size
                        if orig_w > max_dim or orig_h > max_dim:
                            logger.info(f"YÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ gÃ¶rsel saptandÄ± ({orig_w}x{orig_h}). Video modeli iÃ§in kÃ¼Ã§Ã¼ltÃ¼lÃ¼yor...")
                            if orig_w > orig_h:
                                new_w = max_dim
                                new_h = int(orig_h * (max_dim / orig_w))
                            else:
                                new_h = max_dim
                                new_w = int(orig_w * (max_dim / orig_h))
                            
                            # Encode dimensions to multiples of 8
                            new_w = new_w - (new_w % 8)
                            new_h = new_h - (new_h % 8)
                            
                            if img.mode != 'RGB':
                                img = img.convert('RGB')
                                
                            img = img.resize((new_w, new_h), Image.Resampling.LANCZOS)
                            img.save(tmp_path, format="JPEG", quality=95)
                            
                            # Yeniden yÃ¼kle
                            with open(tmp_path, "rb") as f:
                                b64_data = base64.b64encode(f.read()).decode("utf-8")
                            
                            # Data URI oluÅŸturup upload metodunu Ã§aÄŸÄ±rÄ±yoruz
                            upload_res = await self.upload_base64_image(f"data:image/jpeg;base64,{b64_data}")
                            if upload_res.get("success"):
                                image_url = upload_res.get("url")
                                logger.info(f"Optimize edilmiÅŸ gÃ¶rsel yÃ¼klendi: {image_url}")
                    
                    if os_module.path.exists(tmp_path):
                        os_module.remove(tmp_path)
                except Exception as resize_err:
                    logger.warning(f"GÃ¶rsel boyutlandÄ±rma hatasÄ±, orijinali ile devam ediliyor: {resize_err}")

                arguments["image_url"] = image_url
            
            # BazÄ± modeller (Minimax) image_url kabul etmeyebilir veya farklÄ± isimlendirmiÅŸ olabilir, 
            # ancak standart fal.ai wrapperlarÄ± genelde image_url standardÄ±nÄ± destekliyor.
            
            result = await fal_client.subscribe_async(
                selected_endpoint,
                arguments=arguments,
                with_logs=True,
            )
            
            if result and "video" in result:
                return {
                    "success": True,
                    "video_url": result["video"]["url"],
                    "thumbnail_url": result["video"].get("thumbnail_url"),
                    "model": preferred_model,
                    "model_id": selected_endpoint,
                }
            else:
                return {"success": False, "error": f"API yanÄ±tÄ± geÃ§ersiz. SonuÃ§: {result}"}
                
        except Exception as e:
            logger.error(f"âš ï¸ {preferred_model} ({selected_endpoint}) video Ã¼retimi baÅŸarÄ±sÄ±z: {e}")
            return {"success": False, "error": f"Video generation failed: {str(e)}"}
    
    async def _edit_image(self, params: dict) -> dict:
        """
        AkÄ±llÄ± GÃ¶rsel DÃ¼zenleme â€” FLUX Kontext + Auto-Retry.
        
        SÄ±rasÄ±yla dener:
        1. Object Removal (eÄŸer "kaldÄ±r/sil" denildiyse)
        2. FLUX Kontext Pro (AkÄ±llÄ± lokal dÃ¼zenleme â€” en iyi)
        3. OmniGen (Genel dÃ¼zenleme)
        4. Flux Inpainting (Fallback)
        """
        original_prompt = params.get("prompt", "")
        image_url = params.get("image_url", "")
        
        try:
            # 1. Ã‡eviri yap (Ä°ngilizce her zaman daha iyi Ã§alÄ±ÅŸÄ±r)
            english_prompt = original_prompt
            try:
                from app.services.prompt_translator import translate_to_english
                english_prompt, _ = await translate_to_english(original_prompt)
                logger.info(f"ğŸ¨ Edit Prompt: '{original_prompt}' -> '{english_prompt}'")
            except Exception as trans_error:
                logger.warning(f"Prompt Ã§eviri hatasÄ±: {trans_error}. Orijinal prompt kullanÄ±lÄ±yor.")
            
            # 2. "Silme" isteÄŸi mi?
            removal_keywords = ["remove", "delete", "erase", "take off", "clear", "gone"]
            is_removal = any(kw in english_prompt.lower() for kw in removal_keywords)
            
            if is_removal:
                # Prompt'tan nesneyi Ã§Ä±kar (Basit keyword extraction)
                object_to_remove = english_prompt
                for word in ["remove", "delete", "erase", "take off", "the", "from", "image", "photo", "picture", "please"]:
                    object_to_remove = object_to_remove.lower().replace(word, "").strip()
                
                logger.info(f"ğŸ—‘ï¸ Object Removal deneniyor: '{object_to_remove}'")
                
                try:
                    result = await fal_client.subscribe_async(
                        "fal-ai/object-removal",
                        arguments={
                            "image_url": image_url,
                            "prompt": object_to_remove,
                        },
                        with_logs=True,
                    )
                    
                    if result and "image" in result:
                        return {
                            "success": True,
                            "image_url": result["image"]["url"],
                            "model": "object-removal",
                            "method_used": "object_removal"
                        }
                except Exception as e:
                    logger.warning(f"Object Removal hatasÄ±: {e}")

            # 3. FLUX Kontext Pro (AkÄ±llÄ± Lokal DÃ¼zenleme â€” en iyi)
            logger.info(f"ğŸ¯ FLUX Kontext deneniyor: '{english_prompt}'")
            try:
                result = await fal_client.subscribe_async(
                    "fal-ai/flux-pro/kontext",
                    arguments={
                        "prompt": english_prompt,
                        "image_url": image_url,
                        "guidance_scale": 3.5,
                    },
                    with_logs=True,
                )
                
                if result and "images" in result and len(result["images"]) > 0:
                    return {
                        "success": True,
                        "image_url": result["images"][0]["url"],
                        "model": "flux-kontext-pro",
                        "method_used": "kontext"
                    }
            except Exception as e:
                logger.warning(f"FLUX Kontext hatasÄ±: {e}")

            # 4. OmniGen (Instruction Based Fallback)
            logger.info(f"âœ¨ OmniGen deneniyor: '{english_prompt}'")
            try:
                edit_prompt = f"<img><|image_1|></img> {english_prompt}"
                result = await fal_client.subscribe_async(
                    "fal-ai/omnigen-v1",
                    arguments={
                        "prompt": edit_prompt,
                        "input_image_urls": [image_url],
                        "num_images": 1,
                        "image_size": "square_hd",
                        "guidance_scale": 3.0,
                        "num_inference_steps": 50,
                    },
                    with_logs=True,
                )
                
                if result and "images" in result and len(result["images"]) > 0:
                    return {
                        "success": True,
                        "image_url": result["images"][0]["url"],
                        "model": "omnigen-v1",
                        "method_used": "omnigen"
                    }
            except Exception as e:
                logger.warning(f"OmniGen hatasÄ±: {e}")

            # 5. Fallback: Flux Inpainting
            logger.info("ğŸ”§ Flux Inpainting Fallback...")
            return await self._inpainting_flux(image_url, english_prompt if english_prompt else original_prompt)
                
        except Exception as e:
            logger.error(f"EDIT IMAGE KRÄ°TÄ°K HATA: {str(e)}")
            return {"success": False, "error": str(e)}
    
    async def _outpaint_image(self, params: dict) -> dict:
        """
        GÃ¶rseli geniÅŸletme (Outpainting) â€” Fallback zinciri ile.
        
        1. fal-ai/image-apps-v2/outpaint (native outpainting)
        2. Flux Kontext (edit ile format dÃ¶nÃ¼ÅŸÃ¼mÃ¼ â€” fallback)
        """
        image_url = params.get("image_url", "")
        prompt = params.get("prompt", "")
        left = params.get("left", 0)
        right = params.get("right", 0)
        top = params.get("top", 0)
        bottom = params.get("bottom", 0)
        
        if left == 0 and right == 0 and top == 0 and bottom == 0:
            left = right = top = bottom = 256
        
        # Attempt 1: Native outpainting
        try:
            logger.info(f"ğŸ”² Outpainting: L={left} R={right} T={top} B={bottom}")
            
            result = await fal_client.subscribe_async(
                "fal-ai/image-apps-v2/outpaint",
                arguments={
                    "image_url": image_url,
                    "prompt": prompt or "extend the image naturally, maintaining style and composition",
                    "left": left,
                    "right": right,
                    "top": top,
                    "bottom": bottom,
                },
                with_logs=True,
            )
            
            if result and "image" in result:
                return {
                    "success": True,
                    "image_url": result["image"]["url"],
                    "model": "outpaint",
                    "method_used": "outpainting"
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Outpainting baÅŸarÄ±sÄ±z: {e}. Flux Kontext fallback deneniyor...")
        
        # Attempt 2: Flux Kontext fallback
        try:
            if (left + right) > (top + bottom):
                kontext_prompt = f"Extend this image to a wide landscape panoramic format. Add natural continuation of the scenery on both left and right sides. Keep the main subject exactly the same. {prompt}"
            elif (top + bottom) > (left + right):
                kontext_prompt = f"Extend this image to a tall portrait format. Add natural continuation above and below. Keep the main subject exactly the same. {prompt}"
            else:
                kontext_prompt = f"Extend this image outward in all directions. Add natural continuation of the scenery. Keep the main subject exactly the same. {prompt}"
            
            logger.info(f"ğŸ¯ Outpaint Fallback: Flux Kontext ile format dÃ¶nÃ¼ÅŸÃ¼mÃ¼")
            
            result = await fal_client.subscribe_async(
                "fal-ai/flux-pro/kontext",
                arguments={
                    "prompt": kontext_prompt,
                    "image_url": image_url,
                    "guidance_scale": 3.0,
                    "output_format": "png",
                },
                with_logs=True,
            )
            
            if result and "images" in result and len(result["images"]) > 0:
                return {
                    "success": True,
                    "image_url": result["images"][0]["url"],
                    "model": "flux-kontext-pro",
                    "method_used": "kontext_outpaint"
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Kontext outpaint fallback hatasÄ±: {e}")
        
        return {"success": False, "error": "Outpainting baÅŸarÄ±sÄ±z. Hem native outpaint hem Kontext fallback Ã§alÄ±ÅŸmadÄ±."}
    
    async def _apply_style(self, params: dict) -> dict:
        """
        Sanatsal Stil AktarÄ±mÄ± (Style Transfer).
        
        GÃ¶rsele artistik stil uygular:
        - Empresyonizm, kÃ¼bizm, sÃ¼rrealizm, anime, Ã§izgi film...
        - Moodboard'dan stil aktarÄ±mÄ±
        """
        image_url = params.get("image_url", "")
        style = params.get("style", "impressionism")  # Stil adÄ± veya aÃ§Ä±klamasÄ±
        prompt = params.get("prompt", "")
        
        # Style prompt oluÅŸtur
        style_prompt = prompt if prompt else f"Apply {style} art style to this image"
        
        try:
            logger.info(f"ğŸ¨ Style Transfer: '{style}' uygulanÄ±yor")
            
            result = await fal_client.subscribe_async(
                "fal-ai/image-apps-v2/style-transfer",
                arguments={
                    "image_url": image_url,
                    "style": style,
                    "prompt": style_prompt,
                },
                with_logs=True,
            )
            
            if result and "image" in result:
                return {
                    "success": True,
                    "image_url": result["image"]["url"],
                    "model": "style-transfer",
                    "style_applied": style,
                    "method_used": "style_transfer"
                }
            else:
                return {"success": False, "error": "Stil aktarÄ±mÄ± baÅŸarÄ±sÄ±z"}
                
        except Exception as e:
            logger.error(f"Style Transfer hatasÄ±: {e}")
            return {"success": False, "error": str(e)}
    
    async def _upscale_image(self, params: dict) -> dict:
        """GÃ¶rsel upscale (Topaz)."""
        image_url = params.get("image_url", "")
        scale = params.get("scale", 2)
        
        try:
            result = await fal_client.subscribe_async(
                "fal-ai/topaz",
                arguments={
                    "image_url": image_url,
                    "scale": scale,
                    "model": "Standard V2",
                },
                with_logs=True,
            )
            
            if result and "image" in result:
                return {
                    "success": True,
                    "image_url": result["image"]["url"],
                    "model": "topaz",
                }
            else:
                return {"success": False, "error": "Upscale yapÄ±lamadÄ±"}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _upscale_video(self, params: dict) -> dict:
        """Video upscale."""
        video_url = params.get("video_url", "")
        
        try:
            result = await fal_client.subscribe_async(
                "fal-ai/video-upscaler",
                arguments={"video_url": video_url},
                with_logs=True,
            )
            
            if result and "video" in result:
                return {
                    "success": True,
                    "video_url": result["video"]["url"],
                    "model": "video-upscaler",
                }
            else:
                return {"success": False, "error": "Video upscale yapÄ±lamadÄ±"}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _remove_background(self, params: dict) -> dict:
        """Arka plan kaldÄ±r (BiRefNet V2 â€” transparent PNG)."""
        image_url = params.get("image_url", "")
        
        try:
            result = await fal_client.subscribe_async(
                "fal-ai/birefnet/v2",
                arguments={
                    "image_url": image_url,
                    "model": "General Use (Light)",
                    "operating_resolution": "1024x1024",
                    "output_format": "png",
                },
                with_logs=True,
            )
            
            if result and "image" in result:
                return {
                    "success": True,
                    "image_url": result["image"]["url"],
                    "model": "birefnet-v2",
                }
            else:
                return {"success": False, "error": "Arka plan kaldÄ±rÄ±lamadÄ±"}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _face_swap(self, params: dict) -> dict:
        """YÃ¼z deÄŸiÅŸtirme."""
        base_image_url = params.get("base_image_url", "")
        swap_image_url = params.get("swap_image_url", "")
        
        try:
            result = await fal_client.subscribe_async(
                "fal-ai/face-swap",
                arguments={
                    "base_image_url": base_image_url,
                    "swap_image_url": swap_image_url,
                },
                with_logs=True,
            )
            
            if result and "image" in result:
                return {
                    "success": True,
                    "image_url": result["image"]["url"],
                    "model": "face-swap",
                }
            else:
                return {"success": False, "error": "YÃ¼z deÄŸiÅŸimi yapÄ±lamadÄ±"}
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _smart_generate_with_face(self, params: dict) -> dict:
        """
        AkÄ±llÄ± gÃ¶rsel Ã¼retim â€” yÃ¼z kimliÄŸi korumalÄ±.
        
        Grid eklentisindeki kaliteyi chat'e taÅŸÄ±yan strateji:
        0. Arka Plan KaldÄ±rma â€” Referans fotoÄŸraftan arka planÄ± temizle (kÄ±rmÄ±zÄ± alan sÄ±zmasÄ±nÄ± Ã¶nler)
        1. Nano Banana Pro Edit â€” Grid eklentisinin kullandÄ±ÄŸÄ± model (en iyi fotorealizm)
        2. GPT Image 1 Edit â€” ChatGPT modeli (gÃ¼Ã§lÃ¼ fallback)
        3. FLUX Kontext Pro â€” Son alternatif
        """
        import httpx
        import asyncio
        
        prompt = params.get("prompt", "")
        face_image_url = params.get("face_image_url", "")
        aspect_ratio = params.get("aspect_ratio", "1:1")
        resolution = params.get("resolution", "1K")
        
        attempts = []
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã–N Ä°ÅLEM: Arka Plan KaldÄ±rma (BiRefNet)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Referans fotoÄŸraftaki arka planÄ± (kÄ±rmÄ±zÄ± EMRE yazÄ±sÄ± vs.) temizle.
        # Bu Gemini/ChatGPT'nin dahili olarak yaptÄ±ÄŸÄ± iÅŸlemin aynÄ±sÄ±.
        clean_face_url = face_image_url
        logger.info(f"ğŸ§¹ Arka plan kaldÄ±rÄ±lÄ±yor (BiRefNet)...")
        try:
            bg_result = await asyncio.wait_for(
                fal_client.subscribe_async(
                    "fal-ai/birefnet",
                    arguments={
                        "image_url": face_image_url,
                        "model": "General Use (Heavy)",
                        "operating_resolution": "1024x1024",
                        "output_format": "png",
                    },
                    with_logs=True,
                ),
                timeout=15  # 15 saniye limit
            )
            
            if bg_result and "image" in bg_result:
                clean_face_url = bg_result["image"]["url"]
                logger.info(f"âœ… Arka plan kaldÄ±rÄ±ldÄ±! Temiz referans gÃ¶rseli hazÄ±r.")
            else:
                logger.warning(f"âš ï¸ Arka plan kaldÄ±rma sonuÃ§ dÃ¶ndÃ¼rmedi, orijinal gÃ¶rsel kullanÄ±lacak.")
        except Exception as e:
            logger.warning(f"âš ï¸ Arka plan kaldÄ±rma hatasÄ±: {e}. Orijinal gÃ¶rsel kullanÄ±lacak.")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # AÅAMA 1: Nano Banana Pro Edit â€” Grid Eklentisinin Modeli
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Grid eklentisinde mÃ¼kemmel sonuÃ§ veren aynÄ± endpoint.
        # Temiz referans gÃ¶rseli + prompt gÃ¶nderip fotorealistik sonuÃ§ alÄ±r.
        logger.info(f"ğŸ¯ AÅŸama 1: Nano Banana Pro Edit â€” Grid modeli ile Ã¼retim...")
        try:
            result = await asyncio.wait_for(
                fal_client.subscribe_async(
                    "fal-ai/nano-banana-pro/edit",
                    arguments={
                        "prompt": prompt,
                        "image_urls": [clean_face_url],
                        "num_images": 1,
                        "aspect_ratio": aspect_ratio,
                        "output_format": "png",
                        "resolution": resolution or "1K",
                    },
                    with_logs=True,
                ),
                timeout=45
            )
            
            if result and "images" in result and len(result["images"]) > 0:
                image_url = result["images"][0]["url"]
                logger.info(f"âœ… Nano Banana Pro Edit baÅŸarÄ±lÄ±!")
                return {
                    "success": True,
                    "image_url": image_url,
                    "base_image_url": image_url,
                    "method_used": "nano_banana_pro_edit",
                    "quality_notes": "Nano Banana Pro Edit ile fotorealistik gÃ¶rsel Ã¼retildi.",
                    "model_display_name": "Nano Banana Pro",
                    "attempts": ["nano_banana_pro_edit (baÅŸarÄ±lÄ±)"],
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Nano Banana Pro Edit hatasÄ±: {e}")
            attempts.append(f"nano_banana_pro_edit ({str(e)[:80]})")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # AÅAMA 2: GPT Image 1 Edit â€” ChatGPT Modeli (Fallback)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        gpt_size_map = {
            "1:1": "1024x1024",
            "16:9": "1536x1024",
            "9:16": "1024x1536",
            "4:3": "1536x1024",
            "3:4": "1024x1536",
        }
        gpt_image_size = gpt_size_map.get(aspect_ratio, "1024x1024")
        
        logger.info(f"ğŸ–Œï¸ AÅŸama 2: GPT Image 1 Edit â€” ChatGPT modeli ile Ã¼retim...")
        try:
            edit_prompt = f"Create a photorealistic photograph: {prompt}. The person in this photo must look exactly like the person in the reference image â€” same face, skin tone, hair, and features. IMPORTANT: Do NOT copy the framing, pose, or composition from the reference photo. Instead, create a completely new scene with natural composition matching the described scenario. Show the full body or environment as the scene requires, not just a close-up headshot. Discard the original background entirely."
            
            result = await asyncio.wait_for(
                fal_client.subscribe_async(
                    "fal-ai/gpt-image-1/edit-image",
                    arguments={
                        "prompt": edit_prompt,
                        "image_urls": [clean_face_url],
                        "image_size": gpt_image_size,
                        "quality": "high",
                        "input_fidelity": "low",
                        "num_images": 1,
                        "output_format": "png",
                    },
                    with_logs=True,
                ),
                timeout=60  # 60 saniye limit
            )
            
            if result and "images" in result and len(result["images"]) > 0:
                image_url = result["images"][0]["url"]
                logger.info(f"âœ… GPT Image 1 Edit baÅŸarÄ±lÄ±!")
                return {
                    "success": True,
                    "image_url": image_url,
                    "base_image_url": image_url,
                    "method_used": "gpt_image_1_edit",
                    "quality_notes": "GPT Image 1 (ChatGPT modeli) ile yÃ¼z kimliÄŸi korunarak fotorealistik gÃ¶rsel Ã¼retildi.",
                    "model_display_name": "GPT Image 1",
                    "attempts": attempts + ["gpt_image_1_edit (baÅŸarÄ±lÄ±)"],
                }
        except Exception as e:
            logger.warning(f"âš ï¸ GPT Image 1 Edit hatasÄ±: {e}")
            attempts.append(f"gpt_image_1_edit (hata: {str(e)[:80]})")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # AÅAMA 2: FLUX Kontext Pro â€” YÃ¼z KimliÄŸi KorumalÄ± DÃ¶nÃ¼ÅŸÃ¼m
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info(f"ğŸ–Œï¸ AÅŸama 2: FLUX Kontext Pro ile yÃ¼z korumalÄ± Ã¼retim...")
        try:
            kontext_prompt = f"Place this exact person in the following scene, keeping their face, identity, clothing and appearance exactly the same: {prompt}"
            
            result = await asyncio.wait_for(
                fal_client.subscribe_async(
                    "fal-ai/flux-pro/kontext",
                    arguments={
                        "prompt": kontext_prompt,
                        "image_url": clean_face_url,
                        "guidance_scale": 4.0,
                        "output_format": "png",
                    },
                    with_logs=True,
                ),
                timeout=45  # 45 saniye limit
            )
            
            if result and "images" in result and len(result["images"]) > 0:
                image_url = result["images"][0]["url"]
                logger.info(f"âœ… FLUX Kontext Pro baÅŸarÄ±lÄ±!")
                attempts.append("flux_kontext_pro (baÅŸarÄ±lÄ±)")
                return {
                    "success": True,
                    "image_url": image_url,
                    "base_image_url": image_url,
                    "method_used": "flux_kontext_pro",
                    "quality_notes": "FLUX Kontext Pro ile yÃ¼z kimliÄŸi korunarak gÃ¶rsel Ã¼retildi.",
                    "model_display_name": "FLUX Kontext Pro",
                    "attempts": attempts + ["flux_kontext_pro (baÅŸarÄ±lÄ±)"],
                }
        except Exception as e:
            logger.warning(f"âš ï¸ FLUX Kontext Pro hatasÄ±: {e}")
            attempts.append(f"flux_kontext_pro (hata: {str(e)[:80]})")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # AÅAMA 3: Nano Banana Pro â€” Son Ã‡are (YÃ¼z kimliÄŸi korunmaz)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info(f"ğŸ”„ AÅŸama 3: Nano Banana Pro â€” son Ã§are...")
        try:
            result = await self._generate_image({
                "prompt": prompt,
                "aspect_ratio": aspect_ratio,
                "resolution": resolution,
            })
            
            if result.get("success"):
                logger.info(f"âœ… Nano Banana Pro baÅŸarÄ±lÄ± (yÃ¼z entegrasyonsuz)")
                return {
                    "success": True,
                    "image_url": result["image_url"],
                    "base_image_url": result["image_url"],
                    "method_used": "nano_banana_only",
                    "quality_notes": "GPT Image 1 ve FLUX Kontext baÅŸarÄ±sÄ±z oldu. Nano Banana Pro ile Ã¼retildi (yÃ¼z kimliÄŸi korunmadÄ±).",
                    "model_display_name": "Nano Banana Pro",
                    "attempts": attempts + ["nano_banana_pro (baÅŸarÄ±lÄ±)"],
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Nano Banana Pro hatasÄ±: {e}")
            attempts.append(f"nano_banana_pro (hata: {str(e)[:80]})")
        
        return {
            "success": False,
            "error": "TÃ¼m gÃ¶rsel Ã¼retim yÃ¶ntemleri baÅŸarÄ±sÄ±z oldu.",
            "attempts": attempts,
        }


    async def _extract_frame(self, video_url: str) -> dict:
        """Video'dan ilk kareyi Ã§Ä±kar (FFmpeg)."""
        try:
            # fal-ai/ffmpeg-api kullanarak kare Ã§Ä±kar
            # -ss 00:00:01 : 1. saniyeden al (baÅŸlangÄ±Ã§ bazen siyah olabilir)
            command = f"ffmpeg -i {video_url} -ss 00:00:01 -vframes 1 output.png"
            
            result = await fal_client.subscribe_async(
                "fal-ai/ffmpeg-api",
                arguments={"command": command},
                with_logs=True,
            )
            
            if result and "outputs" in result and len(result["outputs"]) > 0:
                return {
                    "success": True,
                    "image_url": result["outputs"][0]["url"],
                    "model": "ffmpeg-api"
                }
            return {"success": False, "error": "Kare Ã§Ä±karÄ±lamadÄ±"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _edit_video(self, params: dict) -> dict:
        """
        AkÄ±llÄ± Video DÃ¼zenleme (Smart Hybrid).
        
        Stratejiler:
        1. Flux Inpainting + Kling (Nesne kaldÄ±rma/deÄŸiÅŸtirme)
        2. Video-to-Video (Stil/Atmosfer deÄŸiÅŸtirme)
        3. OmniGen + Kling (TalimatlÄ± dÃ¼zenleme)
        """
        video_url = params.get("video_url", "")
        instruction = params.get("prompt", "")  # Talimat
        reference_image_url = params.get("image_url")  # Thumbnail/Reference frame
        
        # EÄŸer referans gÃ¶rsel YOKSA, video'dan Ã§Ä±kar!
        if not reference_image_url:
            print("âš ï¸ Video iÃ§in referans gÃ¶rsel (thumbnail) yok. Ã‡Ä±karÄ±lÄ±yor...")
            extract_result = await self._extract_frame(video_url)
            if extract_result["success"]:
                reference_image_url = extract_result["image_url"]
                print(f"âœ… Kare Ã§Ä±karÄ±ldÄ±: {reference_image_url[:60]}...")
            else:
                print("âŒ Kare Ã§Ä±karma baÅŸarÄ±sÄ±z. Video-to-Video fallback yapÄ±lacak.")
        
        instruction_lower = instruction.lower()
        
        # Strateji Belirleme
        if not reference_image_url:
             # GÃ¶rsel yoksa mecburen V2V kullanmalÄ±yÄ±z (Inpainting gÃ¶rsel ister)
             print("âš ï¸ Referans gÃ¶rsel yok, Strategy 2 (V2V) zorunlu seÃ§iliyor.")
             strategy = "strategy_2"
        elif any(keyword in instruction_lower for keyword in ["stil", "style", "yap", "make", "filter", "convert", "transform", "anime", "cartoon"]):
            strategy = "strategy_2"  # Global DÃ¶nÃ¼ÅŸÃ¼m
        elif any(keyword in instruction_lower for keyword in ["kaldÄ±r", "remove", "sil", "delete", "yok et", "change", "deÄŸiÅŸtir", "replace"]):
            strategy = "strategy_1"  # Inpainting (GÃ¶rsel var ise)
        else:
            strategy = "strategy_2"  # VarsayÄ±lan fallback

            
        print(f"ğŸ¬ Video Edit Stratejisi: {strategy} ({instruction})")
        
        try:
            # STRATEJÄ° 1: Hassas Nesne KaldÄ±rma/DeÄŸiÅŸtirme (Inpainting Flow)
            if strategy == "strategy_1" and reference_image_url:
                # 1. Kareyi DÃ¼zenle (Smart Edit Image kullan - iÃ§inde translation ve keyword extraction var)
                print("   1. AdÄ±m: Kare DÃ¼zenleniyor (_edit_image)...")
                # _edit_image zaten "remove" keywordlerini algÄ±layÄ±p "Object Removal" modelini,
                # aksi halde OmniGen'i kullanÄ±yor. Bu Ã§ok daha gÃ¼venli.
                edited_frame = await self._edit_image({
                    "image_url": reference_image_url,
                    "prompt": instruction
                })
                
                if not edited_frame["success"]:
                    print(f"âŒ Kare dÃ¼zenleme hatasÄ±: {edited_frame.get('error')}")
                    return edited_frame
                
                print(f"   âœ… Kare dÃ¼zenlendi: {edited_frame['image_url'][:50]}... (Model: {edited_frame.get('model')})")
                
                # 2. Videoyu Yeniden Ãœret (Kling I2V)
                print("   2. AdÄ±m: Video Yeniden Ãœretiliyor (Kling)...")
                video_result = await self._generate_video({
                    "prompt": instruction, # Veya original prompt
                    "image_url": edited_frame["image_url"],
                    "duration": "5",
                    "aspect_ratio": "16:9" # Videodan alÄ±nmalÄ± aslÄ±nda
                })
                
                if video_result["success"]:
                    video_result["method_used"] = f"edit_frame_{edited_frame.get('model')}_plus_kling"
                return video_result

            # STRATEJÄ° 2: Video-to-Video
            elif strategy == "strategy_2":
                return await self._video_to_video(video_url, instruction)

            # STRATEJÄ° 3: OmniGen + Kling (Fallback)
            else:
                # Reference image varsa OmniGen, yoksa V2V fallback
                if reference_image_url:
                    print("   1. AdÄ±m: Kare DÃ¼zenleniyor (OmniGen)...")
                    edited_frame = await self._edit_image({
                        "image_url": reference_image_url,
                        "prompt": instruction
                    })
                    if not edited_frame["success"]:
                        return edited_frame
                        
                    print("   2. AdÄ±m: Video Yeniden Ãœretiliyor (Kling)...")
                    video_result = await self._generate_video({
                        "prompt": instruction,
                        "image_url": edited_frame["image_url"]
                    })
                    if video_result["success"]:
                        video_result["method_used"] = "omnigen_plus_kling"
                    return video_result
                else:
                    return await self._video_to_video(video_url, instruction)

        except Exception as e:
            return {"success": False, "error": f"Video dÃ¼zenleme hatasÄ±: {str(e)}"}

    async def _inpainting_flux(self, image_url: str, prompt: str) -> dict:
        """Flux Inpainting ile gÃ¶rsel dÃ¼zenle."""
        try:
            result = await fal_client.subscribe_async(
                "fal-ai/flux-general/inpainting",
                arguments={
                    "prompt": prompt,
                    "image_url": image_url,
                    "mask_strategy": "keyword", # Basit keyword bazlÄ± maskeleme (Ã¶rn: "cat")
                    "mask_keywords": prompt,    # Prompt'u keyword olarak kullan
                    "image_size": "landscape_4_3", 
                    "num_inference_steps": 28,
                    "guidance_scale": 3.5,
                    "strength": 1.0 # Tam inpainting
                },
                with_logs=True,
            )
            
            if result and "images" in result and len(result["images"]) > 0:
                return {
                    "success": True,
                    "image_url": result["images"][0]["url"],
                    "model": "flux-inpainting"
                }
            return {"success": False, "error": "Inpainting baÅŸarÄ±sÄ±z"}
        except Exception as e:
            return {"success": False, "error": str(e)}

    async def _video_to_video(self, video_url: str, prompt: str) -> dict:
        """
        Video-to-Video Fallback.
        1. LTX-Video (Genel endpoint)
        2. BaÅŸarÄ±sÄ±z olursa: Ä°lk kareyi al -> Yeni video Ã¼ret (Loop)
        """
        print(f"ğŸ”¥ğŸ”¥ LIVE DEBUG: _video_to_video called with url={video_url}, prompt={prompt}")
        try:
            # 1. LTX-Video (Genel Endpoint - subpath olmadan)
            print("ğŸ¥ Video-to-Video: LTX deneniyor...")
            try:
                result = await fal_client.subscribe_async(
                    "fal-ai/ltx-video", # DoÄŸrudan model ID
                    arguments={
                        "video_url": video_url,
                        "prompt": prompt,
                        "resolution": "1280x720"
                    },
                    with_logs=True,
                )
                print(f"ğŸ”¥ğŸ”¥ LIVE DEBUG: LTX Result: {result}")
                if result and "video" in result:
                    return {
                        "success": True,
                        "video_url": result["video"]["url"],
                        "model": "ltx-video",
                        "method_used": "video_to_video_ltx"
                    }
            except Exception as e:
                print(f"âš ï¸ LTX V2V baÅŸarÄ±sÄ±z ({e}), fallback yapÄ±lÄ±yor...")
                print(f"ğŸ”¥ğŸ”¥ LIVE DEBUG: LTX Exception: {e}")

            # 2. ULTIMATE FALLBACK: Extract Frame + Generate Video
            # HiÃ§bir V2V Ã§alÄ±ÅŸmazsa, videonun ilk karesini alÄ±p yeniden Ã¼retiriz.
            # Bu iÅŸlem asla Ã§Ã¶kmemeli.
            print("ğŸ”„ V2V Fallback: Kare yakala + Yeniden Ã¼ret...")
            extract_res = await self._extract_frame(video_url)
            print(f"ğŸ”¥ğŸ”¥ LIVE DEBUG: Extract Frame Result: {extract_res}")
            
            if extract_res["success"]:
                # Kling ile I2V yap
                return await self._generate_video({
                    "prompt": prompt,
                    "image_url": extract_res["image_url"],
                    "duration": "5",
                    "aspect_ratio": "16:9"
                })
            else:
                return {"success": False, "error": "Video karesi alÄ±namadÄ±, dÃ¼zenleme iptal."}

        except Exception as e:
            return {"success": False, "error": f"Video edit kritik hata: {str(e)}"}

    # ===============================
    # PUBLIC COMPATIBILITY WRAPPERS
    # ===============================

    async def smart_generate_with_face(self, prompt: str, face_image_url: str, aspect_ratio: str = "1:1", resolution: str = "1K") -> dict:
        """AgentOrchestrator uyumluluÄŸu iÃ§in wrapper."""
        return await self._smart_generate_with_face({
            "prompt": prompt,
            "face_image_url": face_image_url,
            "aspect_ratio": aspect_ratio,
            "resolution": resolution
        })

    async def upload_base64_image(self, base64_data: str) -> dict:
        """
        Base64 encoded gÃ¶rseli fal.ai storage'a yÃ¼kle.
        AgentOrchestrator tarafÄ±ndan direkt Ã§aÄŸrÄ±lÄ±r.
        """
        import base64
        import tempfile
        import os as os_module
        
        try:
            # Data URI prefix'ini temizle
            if "," in base64_data:
                base64_data = base64_data.split(",", 1)[1]
            
            # Base64 decode
            image_bytes = base64.b64decode(base64_data)
            
            # Extension belirle
            if base64_data.startswith("iVBORw"): extension = ".png"
            elif base64_data.startswith("/9j/"): extension = ".jpg"
            elif base64_data.startswith("UklGR"): extension = ".webp"
            else: extension = ".png"
            
            # Temp dosyaya yaz
            with tempfile.NamedTemporaryFile(suffix=extension, delete=False) as tmp_file:
                tmp_file.write(image_bytes)
                tmp_path = tmp_file.name
            
            try:
                # fal.ai storage'a yÃ¼kle
                url = fal_client.upload_file(tmp_path)
                return {"success": True, "url": url}
            finally:
                if os_module.path.exists(tmp_path):
                    os_module.remove(tmp_path)
        except Exception as e:
            return {"success": False, "error": str(e)}

# Backward compatibility iÃ§in singleton instance
fal_plugin_v2 = FalPluginV2()
